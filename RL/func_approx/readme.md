# Is the Bellman residual a bad proxy?

Matthieu Geist, Bilal Piot, Olivier Pietquin

Université de Lorraine & CNRS,  Univ. Lille, CNRS, Centrale Lille, Inria

NIPS'17

Citation: 20

# Kernel-Based Reinforcement Learning Using Bellman Residual Elimination

Brett Bethkem, Jonathan P. How, Asuman Ozdaglar

Massachusetts Institute of Technology

JMLR

Citation: 11

# Practical Kernel-Based Reinforcement Learning

Andr´e M. S. Barreto, Doina Precup, Joelle Pineau

Laborat´orio Nacional de Computa¸c˜ao Cient´ıfica, McGill University

Citation: 36

# Reinforcement Learning via Gaussian Processes with Neural Network Dual Kernels

Imène R. Goumiri, Benjamin W. Priest, Michael D. Schneider

Lawrence Livermore National Laboratory

Citation: 3

# Gaussian Processes in Reinforcement Learning

Carl Edward Rasmussen, Malte Kuss

Max Planck Institute

NIPS'03

Citation: 293

Gaussian process regression with RL.

# Reinforcement learning with Gaussian processes

Yaakov Engel, Shie Mannor, Ron Meir

University of Alberta, McGill University, Technion Institute of Technology

ICML'05

Citation: 436

Gaussian Process Temporal Difference(GPTD)

# Nonlinear Inverse Reinforcement Learning with Gaussian Processes

Sergey Levine, Zoran Popovic´, Vladlen Koltun

Stanford University, University of Washington

NIPS'11

Citation: 325

# Sample Efficient Reinforcement Learning with Gaussian Processes

Robert C. Grande, Thomas J. Walsh, Jonathan P. How

Massachusetts Institute of Technology

ICML'14

Citation: 52

# Deterministic Bellman Residual Minimization

Ehsan Saleh, Nan Jiang

University of Illinois at Urbana-Champaign

NIPS'19 Workshop

Citation: 4

# Should one compute the Temporal Difference fix point or minimize the Bellman Residual? The unified oblique projection view

Bruno Scherrer 

INRIA Lorraine

ICML'10

Citation: 92

# A Kernel Loss for Solving the Bellman Equation

Yihao Feng, Lihong Li, Qiang Liu

UT Austin, Google Research

NIPS'19

Citation: 34

# Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path

András Antos, Csaba Szepesvári, Rémi Munos 

Citation: 364

# SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation

Bo Dai, Albert Shaw, Lihong Li, Lin Xiao, Niao He, Zhen Liu, Jianshu Chen, Le Song

Georgia Institute of Technology, Google Inc., Microsoft Research, University of Illinois at Urbana Champaign, Tencent AI Lab

ICML'18

Citation: 165
# Reference

- [DAVID SILVER RL Course](https://www.davidsilver.uk/teaching/)
- [David Silver强化学习公开课中文讲解及实践 知乎](https://www.zhihu.com/column/reinforce)